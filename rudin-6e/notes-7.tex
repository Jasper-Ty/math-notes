\documentclass{article}

\usepackage{mathrsfs}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage[margin=0.5in]{geometry}

\newenvironment{myboxed}{\bigskip\noindent\begin{tabular}{|p{.975\textwidth}|}\hline \\}{\\\\\hline\end{tabular}\bigskip}
\newenvironment{mytitle}{\noindent\large\begin{flushright}}{\end{flushright}\normalsize}

\begin{document}

\begin{mytitle}
    Principles of Mathematical Analysis \\
    Chapter 7 \\
    \normalsize Jasper Ty
\end{mytitle}

\section{Pointwise Convergence}

\begin{myboxed}
    \textsc{Pointwise convergence of functions}

    \textbf{Definition}

    Let $f_n: E \rightarrow \mathbb{R}$ be a sequence of functions. If $f$ is a function such that $f_n(x) \to f(x)$ as $n \to \infty$ for all $x \in E$, then we say $f_n$ converges \textit{pointwise} to $f$.
\end{myboxed}

This type of convergence is very \textit{weak}. It guarantees very little in the way of actually \textit{working with} the limit.

This definition is readily adapted to infinite sums of functions.

\begin{myboxed}
    \textsc{Infinite sums of functions}

    \textbf{Definition}

    If $f$ is a function such that 
    \[\sum_{n=1}^\infty f_n(x) = f(x)\] 
    for all $x \in E$, then we say $f$ is the \textit{sum} of the series $f_n$.
\end{myboxed}

An example of the weakness of pointwise convergence is

\begin{myboxed}
    \textsc{Continuity is not preserved under pointwise convergence}

    \textbf{Example} 

    Let $f_n: [0, 1] \rightarrow [0, 1]$ be defined by
    \[f_n(x) := x^n\]

    Then $f := \lim f_n$ is 
    \[f(x) = \begin{cases}
        0 & x < 1 \\
        1 & x = 1
    \end{cases}\]

    by Theorem 3.20(e)
\end{myboxed}

In this case, a sequence of continuous functions converges to a function that is eminently discontinuous. We use the preceding idea of ``letting $f < 0$ sink and letting $f = 1$ float using the $n^{th}$ power limit'' to show the following.

\begin{myboxed}
    \textsc{Integrability is not preserved under pointwise convergence}

    \textbf{Example}

    \[\lim_{m \to \infty} \lim_{n \to \infty} (\cos m!\pi x ) ^{2n} = \begin{cases}
        0 & x\text{ irrational} \\
        1 & x\text{ rational}
    \end{cases}\]

    If we let 
    \[f_m (x) := \lim_{n \to \infty} (\cos m!\pi x)^{2n}\]
    the above shows that a limit of integrable functions ($\int f_m dx = 0$ for all $m$) may fail to be integrable.

    \textbf{Proof}

    By a similar argument as in the previous example,
    \[\lim_{n \to \infty} (\cos m!x)^{2n} = \begin{cases}
        0 & m!x\text{ is not an integer} \\
        1 & m!x\text{ is an integer} \\
    \end{cases}\]

    Let $x = p/q$ be rational. Then $m!x$ is rational for all $m \geq q$. Let $x$ be irrational, $m!x$ cannot be an integer for any $m$, otherwise we can show a contradiction. Then

    \[\lim_{m \to \infty} \begin{cases}
        0 & m!x\text{ is not an integer} \\
        1 & m!x\text{ is an integer} \\
        \end{cases} = \begin{cases}
        0 & x \text{ irrational} \\
        1 & x \text{ rational} \\
    \end{cases}\]
\end{myboxed}

These two examples show that \textit{properties} of $f_n$ may not pass through the limit to $f$. 

Next, we show that \textit{operations} on $f_n$ may not be passed through the limit to $f$.

\begin{myboxed}
    \textsc{A limit of differentiated functions may not be the differentiated limit of functions}

    \textbf{Example}

    Let 
    \[f_n(x) := \frac{\sin nx}{\sqrt{n}}\]
    Then,
    \[0 = \frac{d}{dx}\left[\lim_{n \to \infty} f_n \right]\neq \lim_{n \to \infty} \left[\frac{d}{dx} f_n\right] = \sqrt{n}\cos nx\]
\end{myboxed}

\begin{myboxed}
    \textsc{A limit of integrated functions may not be the integral of a limit of functions}

    \textbf{Example}

    Let 
    \[f_n(x) := n x(1-x^2)^n\]
    Then
    \[0 = \int_0^1 \left[\lim_{n \to \infty} f_n \right] \neq \lim_{n \to \infty} \left[\int_0^1 f_n \right] = \frac{1}{2} \]
        
\end{myboxed}

\newpage
\section{Uniform convergence}

\begin{myboxed}
    \textsc{Uniform convergence of functions}

    \textbf{Definition}

    Let $f_n: E \rightarrow \mathbb{R}$ be a sequence of functions. 

    If $f$ is a function such that for all $\varepsilon$ there exists $N$ such that
    \[|f_n(x) - f(x)| \leq \varepsilon\]
    for all $x$, we say that $f$ converges \textit{uniformly}.

    This definition carries over to sums of functions (the partial sums must converge to the limit function uniformly).
\end{myboxed}

This is a \textit{much stronger} notion of convergence, as it, in a sense, ``tethers'' together convergence of of all points in the domain. 

There are useful criteria for uniform convergence. These hint at the idea of being able to make sense of the idea of ``distance'' between two functions, which Rudin makes precise later. The first one tells us that uniform convergence of functions corresponds to convergence (via the Cauchy criterion) with respect to a certain kind of metric. 

\begin{myboxed}
    \textsc{Cauchy criterion for uniform convergence}

    \textbf{Theorem}

    $f_n$ converges uniformly on $E$ if and only if there exists an integer $N$ such that for all $m, n \geq N$,
    \[\sup_{x \in E}|f_n(x) - f_m(x)| \leq \varepsilon\]

    \textbf{Proof}

    For the forward implication, let $f_n \rightarrow f$ uniformly, then choose $N$ such that $n \geq N$ implies 
    \[|f_n(x) - f(x)| \leq \frac{\varepsilon}{2}\]
    Then use the triangle inequality.

    For the converse, we note that the criterion is strong enough itself to guarantee $f_n \rightarrow f$ pointwise, hence if we take the inequality
    \[|f_n(x) - f_m(x)| \leq \varepsilon\]
    and let $m \rightarrow \infty$, we recover the original condition for uniform convergence
\end{myboxed}

The next criterion is just a rephrasing of the first definition of uniform convergence in similar terms. It tells us that uniform convergence corresponds to the ``distance'' between two functions vanishing.

\begin{myboxed}
    \textsc{Supremum criterion for uniform convergence}

    \textbf{Theorem}

    $f_n \rightarrow f$ uniformly on $E$ if and only if 
    \[\sup_{x \in E}|f_n(x) - f(x)| \rightarrow 0 \:\text{ as }\: n \rightarrow \infty\]
\end{myboxed}

Next, we show that uniform convergence does not share the same failures as pointwise convergence when it comes to passing through important properties and operations.

We first take continuity.

\begin{myboxed}
    \textsc{Continuity is preserved under uniform convergence}

    \textbf{Theorem}

    Let $f_n$ be a sequence of continuous functions and let $f_n \rightarrow f$ uniformly. Then $f$ is continuous.

    \textbf{Proof}

    Let $\varepsilon > 0$. Let $x \in E$. Consider the inequality
    \[|f(x) - f(t)| \leq |f(x) - f_n(x)| + |f_n(x) - f_n(t)| + |f_n(t) - f(t)|\]
First use uniform convergence to choose $n$ such that $|f(x) - f_n(x)|$ and $|f(t) - f_n(t)|$ are arbitrarily small. 

Then use continuity to choose $\delta$ such that $|f_n(x) - f_n(t)|$ can be made arbitrarily small by letting $|x-t| \leq \delta$.
\end{myboxed}

This however is not an ``if and only if''. A continuous function can be the non-uniform limit of continuous functions. In one case, however, we can use compactness and monotonicity to take enough control such that a sequence of functions can \textit{only} converge uniformly.

\begin{myboxed}
    \textsc{Inferring uniform convergence from pointwise convergence}

    \textbf{Example}
    
    Let $f_n: K \rightarrow \mathbb{R}$ be a sequence of continuous functions, and let $f_n \rightarrow f$ pointwise. Let $f$ be continuous. Impose the two conditions
    \begin{itemize}
        \item Let $K$ be compact
        \item Let $f_n(x) \geq f_{n+1}(x)$ for all $x$ and all $n$
    \end{itemize}
    Then $f_n \rightarrow f$ uniformly.

    \textbf{Proof}

    We must show that, as $n \rightarrow \infty$,
    \[\sup_{x \in E}|f_n(x) - f(x)| \rightarrow 0\]

    To do this, we choose $\varepsilon$ and argue that the set of points for which $|f_n(x) - f(x)| \geq \varepsilon$ can be made empty if we take $n$ large enough. Let this set of exceptional points be $K_n$.


    $K$'s compactness tells us that $K_n$ is compact:
    \begin{itemize}
        \item Because $f_n - f$ is a continuous function and $(\infty, \varepsilon]$ is closed, $K_n$ is closed. (Theorem 4.8; inverse images of closed sets under continuous functions are closed) 
        \item Because $K_n$ is closed, and $K$ is compact, $K_n$ is compact. (Theorem 2.35; closed subsets of compact spaces are compact).
    \end{itemize}

    Moreover, because of the monotonicity of $f_n$, $K_n \supseteq K_{n+1}$. Hence $K_n$ is a sequence of nested compact sets.

    It must be that $\bigcap K_n$ is empty, as $f_n$ converges pointwise to $f$, and so for each $x$, the fact that $|f_n(x) - f| < \varepsilon$ for some $n$ means there must be some $K_n$ it is not a member of.

    But an intersection of nonempty nested compact sets must be nonempty (Theorem 2.36), so there has to be an empty set somewhere in the sequence. Let this set be $K_N$. Then for all $n \geq N$, $K_n$ is empty. This is precisely the $N$ we need to keep the distance between $f_n$ and $f$ below $\varepsilon$.
\end{myboxed}

Restricting our study to continuous, bounded functions (the functions above were bounded because $K$ was compact) gives rise to a very nice structure, one we're already very familiar with: a metric space. (More importantly, a vector space!)

The concept of distance here corresponds with how it has been used in the previous theorems and examples.

\begin{myboxed}
    \textsc{The space of continuous and bounded functions on $X$}

    \textbf{Definition}

    Let $X$ be a metric space. Let $\mathscr{C}(X)$ denote the set of all continuous, bounded, complex-valued functions on $X$.

    Let $f \in \mathscr{C}(X)$. Define the \textit{supremum norm} as follows.
    \[\Vert f \Vert = \sup_{x \in X} |f(x)|\]
    Let $d(f, g)$ for $f, g \in \mathscr{C}(X)$ be induced by the norm; i.e
    \[d(f, g) = \Vert f - g \Vert\]
    This turns $\mathscr{C}(X)$ into a metric space.
\end{myboxed}

This space is complete, and the fact that it is so can be bootstrapped with the previous theorems.

\begin{myboxed}
    \textsc{$\mathscr{C}(X)$ is complete}

    \textbf{Proof}

    Let $f_n$ be a Cauchy sequence in $\mathscr{C}(X)$. Then $f_n$ converges uniformly to a function $f$. Moreover, since each $f_n$ is continuous, $f$ is continuous. That $f$ is bounded follows from the fact that $f = f_n + (f - f_n)$, so $\Vert f \Vert \leq \Vert f_n \Vert + \Vert f - f_n \Vert = \Vert f_n \Vert + \varepsilon$. 

    Hence $f \in \mathscr{C}(X)$. Since $f_n \rightarrow f$ uniformly, $\Vert f - f_n \Vert \rightarrow 0$.

\end{myboxed}

Next, we tackle integration. Uniform convergence allows us to bound $f$ in a, well, uniform way. This, along with a version of the squeeze theorem for integrals, shows us that uniform convergence plays nicely with integration.

\begin{myboxed}
    \textsc{The integral of a uniformly convergent limit is a uniformly convergent limit of integrals}

    \textbf{Theorem}
    Let $f_n \in \mathscr{R}(\alpha)$ on $[a, b]$ for all $n$. Let $f_n \rightarrow f$ uniformly. Then $f \in \mathscr{R}(\alpha)$, and
    \[\int_a^b f d\alpha = \lim_{n \to \infty} \int_a^b f_n d\alpha\]

    \textbf{Proof}

    The idea is that you can ``squeeze'' $f$ with two $f_n$ shaped calipers, and that the gap decreases as $n$ goes to infinity.

    Let this gap be 
    \[\varepsilon_n = \sup_{x \in [a,b]} |f_n(x) - f(x)|\]
    Then
    \[f_n - \varepsilon_n \leq f \leq f_n + \varepsilon_n\]
    Then this bounds $f$'s lower and upper integrals.
    \[\int_a^b (f_n-\varepsilon_n) d\alpha \leq \underline{\int} f d\alpha \leq \overline{\int} f d\alpha \leq \int_a^b (f_n+\varepsilon_n) d\alpha\]
    Then
    \[0 \leq \overline{\int} f d\alpha - \underline{\int} fd\alpha \leq 2 \varepsilon(\alpha(b) - \alpha(a)) \]
    So $f \in \mathscr{R}(\alpha)$. From the inequality we can also read off 
    \[\left| \int_a^b fd\alpha - \int_a^b f_nd\alpha\right| \leq \varepsilon_n (\alpha(b) - \alpha(a))\]
    Which proves the equality of the integral and the limit.
\end{myboxed}

\newpage
    
Finally, we look at differentiation.

\begin{myboxed}
    \textsc{A sequence of functions whose derivatives converge uniformly converges uniformly to a limit with the correct derivative}

    \textbf{Theorem}

    Let $f_n: [a,b] \rightarrow \mathbb{R}$ be a sequence of differentiable functions that converge pointwise for at least \textit{some} point $x_0$. Then if $f_n'$ converge uniformly, there is a function $f$ such that $f_n \rightarrow f$ uniformly and such that $f_n' \rightarrow f'$.

    \textbf{Proof}

    Let $\varepsilon > 0$. Use the Cauchy criterion for both ordinary sequences in $\mathbb{R}$ and for uniformly convergent sequences of functions to produce $N$ such that $n, m \geq N$ implies
    \[|f_n(x_0) - f_m(x_0)| \leq \frac{\varepsilon}{2}\]
    \[\sup_{t \in [a,b]}|f'_n(t) - f'_m(t)| \leq \frac{\varepsilon}{2(b-a)}\]
    Consider the function $f_n - f_m$, whose derivative is $f'_n - f'_m$. The mean value theorem gives us a $c$ with which we can show
    \[\left|\frac{[f_n(x) - f_m(x)] - [f_n(y) - f_m(y)]}{x-y}\right| = |f'_n(c) - f'_m(c)| \leq \sup_{t \in [a, b]} |f'_n(t) - f'_m(t)| \leq \frac{\varepsilon}{2(b-a)}\]
    Then, since $a \leq x < y \leq b$
    \[\left|[f_n(x) - f_m(x)] - [f_n(y) - f_m(y)]\right| \leq \frac{\varepsilon|x-y|}{2(b-a)} \leq \frac{\varepsilon}{2}\]
    for any $x, y \in [a, b]$. Then, by the triangle inequality,
    \[|f_n(x) - f_m(x)| \leq |[f_n(x) - f_m(x)] - [f_n(x_0) - f_m(x_0)]| + |f_n(x_0) - f_m(x_0)| \leq \varepsilon\]
    Then $f_n$ converges uniformly by the Cauchy criterion.

    Next we prove that the derivative of the limit is the limit of the derivatives. Let $f_n \rightarrow f$. Define the difference quotients
    \[\phi_n(t) := \frac{f_n(t) - f_n(x)}{t-x}\]
    \[\phi(t) := \frac{f(t) - f(x)}{t-x}\]
    Reusing the same inequality, we know that for $n, m \geq N$
    \[|\phi_n(t) - \phi_m(t)| \leq \frac{\varepsilon}{2(b-a)}\]
    So that $\phi_n \rightarrow \phi$ uniformly. Then, by Theorem 7.11, the limits we are interested in commute:
    \[\lim_{t \to x} \lim_{n \to \infty} \phi_n(t) = \lim_{n \to \infty} \lim_{t \to x} \phi_n(t)\]
    The left hand side is
    \[\lim_{t \to x} \lim_{n \to \infty} \phi_n(t) = \lim_{t \to x} \phi(t) = f'(x)\]
    The right hand side is
    \[\lim_{n \to \infty} \lim_{t \to x} \phi_n(t) = \lim_{n \to \infty} f'_n(t)\]
    Hence $f'_n \rightarrow f_n$.
\end{myboxed}

Now with the machinery of limits of function sequences, we can explore a wider variety of functions. As an example.

\begin{myboxed}
    \textsc{A nowhere differentiable continuous function}

    \textbf{Example}

    Define the periodic triangle function $\varphi$ to be
    \[\varphi(x) := |x|\]
    for $0 < x \leq 1$, and let its periodicity be defined by
    \[\varphi(x+2) := \varphi(x)\] 
    Then $\varphi$ is continuous. Define $f$ as
    \[f(x) := \sum_{n=0}^\infty \left(\frac{3}{4}\right)^n \varphi(4^nx)\]
    By Theorem 7.10, the series converges uniformly. Then $f$ is continuous, as it is a uniformly convergent sequence of continuous functions.
     To prove it is not differentiable, we construct a sequence $x_n \rightarrow x$ such that the difference quotient diverges.
\end{myboxed}


\section{Equicontinuous families of functions}

\end{document}
